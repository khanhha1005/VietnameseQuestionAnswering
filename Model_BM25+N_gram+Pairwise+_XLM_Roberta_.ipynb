{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Data của PRETRAIN MODEL :\n",
        "\n",
        "https://drive.google.com/drive/folders/1pnBFj0KaPx90BUit67s1vU-FmSNFrIwd?usp=sharing\n",
        "# Notebook Phải sử dụng GPU"
      ],
      "metadata": {
        "id": "g3WcEhPTQ1qD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmUo4ACPnI_-",
        "outputId": "f2998bbc-15b1-4549-ed32-2bba2a5e9234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VietnameseQuestionAnswering'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 46 (delta 2), reused 40 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), 23.82 MiB | 13.42 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/khanhha1005/VietnameseQuestionAnswering.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SU61yPcnHrB",
        "outputId": "a7920e48-b4bc-489c-d63a-6a1376eb8955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VietnameseQuestionAnswering/Model BM25+N-gram+Pairwise+ XLM Roberta\n"
          ]
        }
      ],
      "source": [
        "%cd /content/VietnameseQuestionAnswering/Model BM25+N-gram+Pairwise+ XLM Roberta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hleudCA2EXDY",
        "outputId": "3d81aff5-555c-413b-c281-2a843ba48cf4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zgJ5uZ_znGF5"
      },
      "outputs": [],
      "source": [
        "# ignore warning \"UserWarning: You seem to be using the pipelines sequentially...\"\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gaeGxn7ngkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61732950-2509-481f-8b63-959626d3f006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11171298 sha256=ec06c5dd8cbae9824e8e7b98a2885032b577b59d850646568e86bfcba5c0161e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.1-cp310-cp310-linux_x86_64.whl size=772708 sha256=54c99f651aed557dbf8e144777b962ff0862f2471a20db5efa5b96390dee9501\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yvajay1x/wheels/ab/a6/5e/97f7c5d6d48b4a52714bb8a66dffe9fb6b2340e1b05c3c23ea\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.6.1-py3-none-any.whl size=107965 sha256=2f2ee22cec5b9c82c384d34ea5f4930cea2024198cfa7728df4a9cde8ca82abf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yvajay1x/wheels/4c/0b/cf/56dfc36d3435f2c1bb75d3a8bf5eb8ff239735d11c78699f00\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=4dc6fa86e7f090587125d68000bb10b9b35292b934ba4620b29c9004c8939eac\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8s86dJTnGF8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import dill\n",
        "import difflib\n",
        "import jellyfish\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from copy import copy\n",
        "from tqdm import tqdm\n",
        "from model.utils import remove_accents, norm_text\n",
        "import torch\n",
        "#XLM-Roberta\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from model.reader.base import Question\n",
        "#BM25\n",
        "from model.retriever.pyserini_retriever import retriever, build_searcher\n",
        "#################\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "from underthesea import text_normalize\n",
        "from model.utils import s1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcUn7OD3nGF8"
      },
      "outputs": [],
      "source": [
        "# load config from config file\n",
        "import json\n",
        "with open('/content/VietnameseQuestionAnswering/config.json') as f:\n",
        "    args = json.load(f)\n",
        "class Args:\n",
        "    def __init__(self, args):\n",
        "        self.__dict__.update(args)\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.__dict__)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.__dict__)\n",
        "args = Args(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQUtWCznnGF9"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "JdjvdR28JuV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load DATA PRETRAIN MODEL"
      ],
      "metadata": {
        "id": "azaoQKKU5hc3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmUtaQH8nGF9"
      },
      "outputs": [],
      "source": [
        "# LOAD PRETRAIN\n",
        "# Retriever\n",
        "args.index_path = \"/content/drive/MyDrive/code/saved_models/indexes/wikipedia_20220620\"\n",
        "searcher = build_searcher(args)\n",
        "# Reader\n",
        "model_name_or_path = \"/content/drive/MyDrive/code/saved_models/vi-mrc-base\"\n",
        "# model_name_or_path = \"/content/drive/MyDrive/code/saved_models/vi-mrc-large\"\n",
        "\n",
        "tokenizer_qa = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "model_qa = AutoModelForQuestionAnswering.from_pretrained(model_name_or_path)\n",
        "#XLM-RoBERTa\n",
        "nlp = pipeline('question-answering', model=model_qa,\n",
        "               tokenizer=tokenizer_qa, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# SentenceTransformer\n",
        "model_st = SentenceTransformer(\n",
        "    '/content/drive/MyDrive/code/saved_models/vn_sbert/phobert_base_mean_tokens_NLI_STS').eval().to(device)\n",
        "\n",
        "zac2022_titles = open(\n",
        "    \"/content/drive/MyDrive/code/saved_models/data/wikipedia_20220620_all_titles_links.txt\", 'r', encoding='utf-8').readlines()\n",
        "zac2022_titles = [title.strip() for title in zac2022_titles\n",
        "                  if not \"(định hướng)\" in title and not \"(Định hướng)\" in title]\n",
        "zac2022_links = json.load(\n",
        "    open(\"/content/drive/MyDrive/code/saved_models/data/wikipedia_20220620_all_links.json\", \"r\", encoding=\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiền xử lý dữ liệu"
      ],
      "metadata": {
        "id": "YoHuo1iz2snc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Xử lý text\n",
        "def normalizer(text):\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "\n",
        "    text = norm_text(text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "def n_gram(tokens, n):\n",
        "    ngrams = []\n",
        "    for i in range(len(tokens) - n + 1):\n",
        "        ngrams.append(' '.join(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "\n",
        "def remove_dublicated(text):\n",
        "    text = text.split(' ')\n",
        "    substring = [text[i]\n",
        "                 for i in range(len(text)) if text[i] not in text[i+1:]]\n",
        "    return ' '.join(substring)"
      ],
      "metadata": {
        "id": "xgtH24t5R19n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEJu2mb8nGF-"
      },
      "outputs": [],
      "source": [
        "  def get_all_candidates(query, sentences):\n",
        "    \"\"\"\n",
        "        :param query: query string\n",
        "        :param sentences: list of normalized sentences\n",
        "        :return: list of candidates\n",
        "    \"\"\"\n",
        "    query = text_normalize(query)\n",
        "    query_tokens = query.lower().split(' ')\n",
        "\n",
        "    candidates = sentences[:]\n",
        "    for i in range(1, len(query_tokens) + 1):\n",
        "        next_candidates = set()\n",
        "        for piece in n_gram(query_tokens, i):\n",
        "            piece_tokens = set(piece.split(' '))\n",
        "            for sent in candidates:\n",
        "                if i == 1:\n",
        "                    if piece in sent.lower():\n",
        "                        next_candidates.add(sent)\n",
        "                else:\n",
        "                    sent_tokens = set(sent.lower().split(' '))\n",
        "                    if len(piece_tokens.union(sent_tokens)):\n",
        "                        next_candidates.add(sent)\n",
        "        if len(next_candidates) == 0:\n",
        "            break\n",
        "        candidates = next_candidates\n",
        "    return list(candidates)\n",
        "\n",
        "def get_closest_candidates(query, sentences, n=1):\n",
        "    candidates = get_all_candidates(query, sentences)\n",
        "    if len(candidates) == 0:\n",
        "        return None\n",
        "    return difflib.get_close_matches(query, candidates, n=n, cutoff=0.0)\n",
        "\n",
        "def custom_matches(a, b, ngram):\n",
        "    a_pieces = n_gram(a, ngram)\n",
        "    b_pieces = n_gram(b, ngram)\n",
        "    count = 0\n",
        "    for piece in a_pieces:\n",
        "        if piece in b_pieces:\n",
        "            count += 1\n",
        "    return count / np.mean([len(a_pieces), len(b_pieces)])\n",
        "\n",
        "\n",
        "\n",
        "# Xử lý candidates\n",
        "def get_link(candidates, zac2022_links, title=\"wiki\"):\n",
        "    link = {}\n",
        "    for candidate in candidates:\n",
        "        if title in zac2022_links[candidate]:\n",
        "            link[candidate] = zac2022_links[candidate][title]\n",
        "        elif \"wiki\" in zac2022_links[candidate]:\n",
        "            link[candidate] = zac2022_links[candidate][\"wiki\"]\n",
        "        else:\n",
        "            last_key = list(zac2022_links[candidate].keys())[0]\n",
        "            link[candidate] = zac2022_links[candidate][last_key]\n",
        "    return link\n",
        "\n",
        "def get_majority_vote(candidates, weights=[4, 2, 2, 2, 2, 1, 1, 1, 1, 1], similar_threshold=0.5, ngram=None):\n",
        "    if weights is None:\n",
        "        weights = np.ones(len(candidates))\n",
        "\n",
        "    def norm(input_str):\n",
        "        # remove special charactersca\n",
        "        input_str = re.sub(f'[^a-zA-Z0-9{s1} ]', '', input_str)\n",
        "        return input_str\n",
        "\n",
        "    # assert len(candidates) == len(weights), 'candidates and weights must have the same length'\n",
        "    if len(candidates) != len(weights):\n",
        "        return None\n",
        "\n",
        "    candidate_lengths = [len(c.split(' ')) for c in candidates]\n",
        "    normed_candidates = [norm(c.lower()) for c in candidates]\n",
        "    normed_candidates = [c.replace(\"bullet\", \"\") for c in normed_candidates]\n",
        "    normed_candidates = [(i, c0, c, w) for i, (c0, c, w) in enumerate(\n",
        "        zip(candidates, normed_candidates, weights)) if len(c) > 0]\n",
        "    indexes, candidates, normed_candidates, weights = zip(*normed_candidates)\n",
        "\n",
        "    if ngram is None:\n",
        "        ngram = np.ceil(np.median(candidate_lengths)).astype(int)\n",
        "    if np.mean(candidate_lengths) < 2:\n",
        "        ngram = 1\n",
        "\n",
        "    # consider the first one\n",
        "    if normed_candidates[0] in normed_candidates[1:]:\n",
        "        _candidates = []\n",
        "        for i, n in enumerate(normed_candidates[1:]):\n",
        "            if normed_candidates[0] in n:\n",
        "                _candidates.append((i+1, n))\n",
        "        avg_len = np.ceil(np.mean([len(c.split(' ')) for _, c in _candidates]))\n",
        "        for i, c in _candidates:\n",
        "            if len(c.split(' ')) > avg_len:\n",
        "                return (i, candidates[0])\n",
        "        return (0, candidates[0])\n",
        "\n",
        "    position = {normed_candidates[0]: [0]}\n",
        "    count_votes = {normed_candidates[0]: weights[0]}\n",
        "    for i in range(1, len(normed_candidates)):\n",
        "        flag = False\n",
        "        for k in count_votes.keys():\n",
        "            if custom_matches(normed_candidates[i], k, ngram) >= similar_threshold:\n",
        "                count_votes[k] += weights[i]\n",
        "                flag = True\n",
        "                position[k].append(i)\n",
        "                break\n",
        "        if not flag:\n",
        "            count_votes[normed_candidates[i]] = weights[i]\n",
        "            position[normed_candidates[i]] = [i]\n",
        "\n",
        "    best_normed_candidate = sorted(\n",
        "        count_votes.keys(), key=lambda x: count_votes[x], reverse=True)[0]\n",
        "    candidates = [candidates[i] for i in position[best_normed_candidate]]\n",
        "    indexes = [indexes[i] for i in position[best_normed_candidate]]\n",
        "    candidate_lengths = [len(c.split(' ')) for c in candidates]\n",
        "    avg_len = np.ceil(np.mean(candidate_lengths))\n",
        "    for i, c in zip(indexes, candidates):\n",
        "        if len(c.split(' ')) == avg_len:\n",
        "            return (i, c)\n",
        "    return (0, candidates[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMsilTMLnGF_"
      },
      "outputs": [],
      "source": [
        "top_k = 10\n",
        "w_read = 0.6\n",
        "w_rank = 0.2\n",
        "w_sim = 0.2\n",
        "\n",
        "# threshold = 0.7\n",
        "# sim_threshold = 0.5\n",
        "# read_threshold = 0.35\n",
        "# rank_threshold = 0.5\n",
        "# dist_threshold = 0.5\n",
        "\n",
        "threshold = 0.1\n",
        "sim_threshold = 0.1\n",
        "read_threshold = 0.1\n",
        "rank_threshold = 0.1\n",
        "dist_threshold = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdcilV2CnGGA"
      },
      "outputs": [],
      "source": [
        "def get_answer(question, category='wiki'):\n",
        "    if question[-1] != \"?\":\n",
        "        question += \" ?\"  # add question mark if not exist\n",
        "\n",
        "    question = Question(question, language='vi')\n",
        "\n",
        "    # Retriever\n",
        "    contexts = retriever(question, searcher, top_k)\n",
        "\n",
        "    # Reader\n",
        "    results = []\n",
        "    _contexts = []\n",
        "\n",
        "    # norm c.score to [0, 1]\n",
        "    max_score = max([c.score for c in contexts])\n",
        "    min_score = min([c.score for c in contexts])\n",
        "    for c in contexts:\n",
        "        c.score = (c.score - min_score) / (max_score - min_score)\n",
        "\n",
        "    for rank, c in enumerate(contexts):\n",
        "        lines = c.text.splitlines()\n",
        "        rank_score = c.score\n",
        "        for line in lines:\n",
        "            context = line.strip()\n",
        "            if not len(context):\n",
        "                continue\n",
        "            _contexts.append([c.title, rank_score, context])\n",
        "\n",
        "    for title, rank_score, _context in _contexts:\n",
        "        QA_input = {\n",
        "            'question': question.text,\n",
        "            'context': _context\n",
        "        }\n",
        "\n",
        "        res = nlp(QA_input)\n",
        "        wiki_link = None\n",
        "        results.append([title,\n",
        "                        remove_dublicated(res['answer']),\n",
        "                        res['score'],\n",
        "                        res['score'], rank_score,\n",
        "                        _context,\n",
        "                        wiki_link,\n",
        "                        res['start'],\n",
        "                        res['end'],\n",
        "                        None,\n",
        "                        ])\n",
        "\n",
        "    query = question.text\n",
        "    if category == \"wiki\":\n",
        "        sents = [\"_\".join(r[0].split(\"_\")[:-1]) + \" . \" + r[5]\n",
        "                 for r in results]\n",
        "    else:\n",
        "        sents = [r[5] for r in results]\n",
        "    sents_embeddings = model_st.encode(\n",
        "        [query] + sents, show_progress_bar=False)\n",
        "    query_embedding = sents_embeddings[0]\n",
        "    sents_embeddings = sents_embeddings[1:]\n",
        "\n",
        "    dists = pairwise_distances(query_embedding.reshape(\n",
        "        1, -1), sents_embeddings, metric='cosine')[0]\n",
        "    dists = 1 - dists\n",
        "\n",
        "    # norm dists to [0, 1]\n",
        "    dists = (dists - dists.min()) / (dists.max() - dists.min())\n",
        "\n",
        "    # norm read_score to [0, 1]\n",
        "    read_scores_max = max([r[3] for r in results])\n",
        "    read_scores_min = min([r[3] for r in results])\n",
        "\n",
        "    for i, r in enumerate(results):\n",
        "        distance = dists[i]\n",
        "        if distance < sim_threshold:\n",
        "            distance = 0\n",
        "        r.append(distance)\n",
        "\n",
        "        results[i][3] = (r[3] - read_scores_min) / \\\n",
        "            (read_scores_max - read_scores_min)\n",
        "\n",
        "    for i in range(len(results)):\n",
        "        if results[i][3] < read_threshold:\n",
        "            results[i][3] = 0\n",
        "\n",
        "        if results[i][4] < rank_threshold:\n",
        "            results[i][4] = 0\n",
        "\n",
        "    results = [[t, a, s * w_read + rs * w_rank + d * w_sim, as_, rs, c, wiki_link, d, start, end, candidates]\n",
        "               for t, a, s, as_, rs, c, wiki_link, start, end, candidates, d in results]\n",
        "\n",
        "    if len(results) == 0:\n",
        "        results.append([\"null\", 0, 0, 0, \"null\"])\n",
        "\n",
        "    # norm score to [0, 1]\n",
        "    max_score = max([r[2] for r in results])\n",
        "    min_score = min([r[2] for r in results])\n",
        "    for r in results:\n",
        "        r[2] = (r[2] - min_score) / (max_score - min_score)\n",
        "\n",
        "        if r[2] < threshold:\n",
        "            r[2] = 0\n",
        "\n",
        "    df = pd.DataFrame(results, columns=['title',\n",
        "                      'answer', 'score', 'reader_score',\n",
        "                                        'rank_score', 'context',\n",
        "                                        'wiki_link', 'dists', 'start', 'end',\n",
        "                                        'candidates',\n",
        "                                        ])\n",
        "\n",
        "    # df = df[df['score'] > 0].reset_index(drop=True)\n",
        "    df = df.sort_values(by=['score'], ascending=False)\n",
        "\n",
        "    # rerank\n",
        "    df['reranked'] = [0] * len(df)\n",
        "\n",
        "\n",
        "    # reorder columns\n",
        "    df = df[['reranked', 'title', 'answer', 'candidates', 'score', 'reader_score',\n",
        "             'rank_score', 'dists', 'start', 'end', 'wiki_link', 'context']]\n",
        "    df.index.name = 'rank'\n",
        "    df = df.reset_index()\n",
        "    if category == \"wiki\":\n",
        "        candidates = get_closest_candidates(\n",
        "            normalizer(df.iloc[0]['answer']), zac2022_titles, n=1)\n",
        "        candidate_links = get_link(candidates, zac2022_links, \"_\".join(\n",
        "            df.iloc[0]['title'].split(\"_\")[:-1]))\n",
        "\n",
        "        df.loc[0, 'candidates'] = candidate_links[candidates[0]]\n",
        "    return df\n",
        "\n",
        "\n",
        "def formate_answer(answers, top_k=10, category='wiki'):\n",
        "    results = []\n",
        "    _results = []\n",
        "    for i, row in answers[:top_k].iterrows():\n",
        "        answer = row['answer']\n",
        "        candidates = row['candidates']\n",
        "        score = row['score']\n",
        "        reader_score = row['reader_score']\n",
        "        rank_score = row['rank_score']\n",
        "        context = row['context']\n",
        "\n",
        "        if answer == \"null\":\n",
        "            results.append(None)\n",
        "        if category == 'wiki':\n",
        "            if candidates:\n",
        "                results.append(candidates)\n",
        "            else:\n",
        "                results.append(None)\n",
        "        else:\n",
        "            results.append(None)\n",
        "\n",
        "    _results = sorted(_results, key=lambda x: x[1] + x[2] + x[3], reverse=True)\n",
        "    for r in _results:\n",
        "        results.append(r[0])\n",
        "\n",
        "    results = list(dict.fromkeys(results))  # remove duplicate and keep order\n",
        "    return {\n",
        "        \"answers\": results,\n",
        "        \"raw_answers\": answers[\"answer\"].tolist(),\n",
        "    }\n",
        "\n",
        "def predict(question):\n",
        "    # Classifier\n",
        "    category='wiki'\n",
        "    df = get_answer(question, category)\n",
        "    ans = formate_answer(df, top_k=top_k, category=category)\n",
        "    return ans['answers'][0] if len(ans['answers']) > 0 else None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN TEST DATA"
      ],
      "metadata": {
        "id": "ayEVvYDH2zeH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWMewnx_nGGB"
      },
      "outputs": [],
      "source": [
        "save_dir = \"/result\"\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "data_questions = json.load(\n",
        "    open(\"/content/drive/MyDrive/code/saved_models/data/zac2022/zac2022_testa_sample_submission.json\", \"r\", encoding=\"utf-8\"))\n",
        "\n",
        "total_question = data_questions['_count_']\n",
        "test_cases = data_questions['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Nh6vEolnGGB"
      },
      "outputs": [],
      "source": [
        "all_predicted_time = []\n",
        "all_result = []\n",
        "\n",
        "for item in tqdm(test_cases, total=total_question, desc=\"Predicting\"):\n",
        "    t1 = time.time()\n",
        "    question_id = item['id']\n",
        "    question = item['question']\n",
        "    answer = predict(question)\n",
        "    t2 = time.time()\n",
        "    predicted_time = int(t2*1000 - t1*1000)\n",
        "    all_predicted_time.append((question_id, predicted_time))\n",
        "    all_result.append({\n",
        "        \"id\": question_id,\n",
        "        \"question\": question,\n",
        "        \"answer\": answer\n",
        "    })\n",
        "\n",
        "submission = {\"data\": all_result}\n",
        "with open(os.path.join(save_dir, \"jupyter_submission.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(submission, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "df_all_predicted_time = pd.DataFrame(all_predicted_time, columns=['id', 'predicted_time'])\n",
        "df_all_predicted_time.to_csv(os.path.join(save_dir, \"jupyter_predicted_time.csv\"), index=False, header=False)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Mode"
      ],
      "metadata": {
        "id": "5V8pSkOYmpn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict('Bác Hồ sinh ra ở đâu')"
      ],
      "metadata": {
        "id": "eiy70TrVmqih"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "S6zoTOSbmlmb"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6813c2ddd2a5746eeecbdb418bcff4174202cb90a311d03b6a1125d4f8afb7f7"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}